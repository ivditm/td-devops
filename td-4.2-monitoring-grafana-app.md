# üß™ TD-4.1 ‚Äì D√©ployer Grafana Alloy sur une app  et monitorer sa machine

## 1) Pr√©-requis

**Poste √©tudiant**

* Docker + Docker Compose
* Un navigateur
* (Option) `curl`
* Python ((pas compliqu√© normalement ;) )

**C√¥t√© Grafana Cloud**

* Un compte Grafana Cloud (free account)
* Un ‚Äústack‚Äù avec :

  * **Metrics** (Prometheus remote_write)
  * **Logs** (Loki)
  
* Un **API Token** (Write: Metrics + Write: Logs)
  
* Les infos ‚ÄúEndpoints‚Äù :
  * Remote write URL (metrics)
  * Loki push URL (logs)
  * Username/Instance ID (souvent un num√©ro) + Token

---

## 2) Architecture du TD

On lance en local (Compose) :

1. `demo-app` : app HTTP + `/metrics` (Prometheus format) + logs JSON sur stdout
2. `prometheus` : scrape `demo-app` (optionnel, utile pour valider localement)
3. `alloy` : collecte m√©triques + logs et envoie vers **Grafana Cloud Metrics** + **Grafana Cloud Logs (Loki)**

**Flux**

* Metrics : `demo-app` ‚Üí Alloy (scrape) ‚Üí Remote Write ‚Üí Grafana Cloud
* Logs : `demo-app stdout` ‚Üí Alloy (docker logs) ‚Üí Loki push ‚Üí Grafana Cloud

> Remarque : on pourrait faire sans Prometheus local (Alloy scrape direct). Je te donne une version ‚Äúsimple et robuste‚Äù : Alloy scrape direct + Prometheus local en bonus de debug.

---

## 3) L‚Äôapp de d√©mo : m√©triques + logs ‚ÄúDataOps‚Äù

### Endpoints fonctionnels

* `GET /` : OK + log ‚Äúrequest‚Äù
* `GET /work?items=100` : simule un mini pipeline DataOps (traitement de N ‚Äúitems‚Äù)

  * incr√©mente `dataops_items_total`
  * peut g√©n√©rer des erreurs de validation
  * enregistre latence + statut

### M√©triques expos√©es (exemples)

* `http_requests_total{route,method,status}`
* `http_request_duration_seconds_bucket{route,...}` (histogram)
* `dataops_items_total{result="ok|invalid"}`
* `dataops_batch_duration_seconds` (histogram)
* `app_build_info{version="1.0.0"}`

### Logs JSON (exemples)

* `{"level":"info","msg":"request","route":"/work","status":200,"items":100,"duration_ms":42,"trace_id":"..."}`
* `{"level":"warn","msg":"validation_failed","invalid_items":7,"batch_id":"..."}`
* `{"level":"error","msg":"upstream_timeout","dependency":"warehouse-api"}`

---

## 4) Fichiers fournis aux √©tudiants

### 4.1 `docker-compose.yml`

> Les √©tudiants compl√®tent uniquement le `.env` Grafana Cloud.

```yaml
services:
  demo-app:
    build: ./demo-app
    container_name: demo-app
    ports:
      - "8080:8080"
    environment:
      - APP_NAME=demo-app
      - APP_VERSION=1.0.0
      - LOG_FORMAT=json
    labels:
      - "com.example.service=demo-app"

  # Optionnel: utile pour v√©rifier localement le scrape
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    depends_on:
      - demo-app

  alloy:
    image: grafana/alloy:latest
    container_name: alloy
    command: ["run", "--server.http.listen-addr=0.0.0.0:12345", "/etc/alloy/config.alloy"]
    ports:
      - "12345:12345" # UI/health Alloy
    volumes:
      - ./alloy/config.alloy:/etc/alloy/config.alloy:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    env_file:
      - ./.env
    depends_on:
      - demo-app
```

---

### 4.2 `.env` (√† compl√©ter avec leurs valeurs Grafana Cloud)

```bash
    # Grafana Cloud - Metrics (Prometheus remote_write)
    GC_METRICS_URL=__REMOTE_WRITE_URL__
    GC_METRICS_USER=__INSTANCE_ID_OR_USER__
    GC_TOKEN=__GRAFANA_CLOUD_TOKEN__

    # Grafana Cloud - Logs (Loki)
    GC_LOKI_URL=__LOKI_PUSH_URL__
    GC_LOKI_USER=__INSTANCE_ID_OR_USER__
```

> Souvent `GC_METRICS_USER` et `GC_LOKI_USER` sont identiques (instance id). Le token peut √™tre le m√™me si le scope le permet.

---

### 4.3 Config Alloy `alloy/config.alloy`

```yaml
    // ========== METRICS: scrape demo-app ==========
    prometheus.scrape "demo_app" {
    targets = [
        { "__address__" = "demo-app:8080", "job" = "demo-app" },
    ]
    forward_to = [prometheus.remote_write.grafana_cloud.receiver]
    scrape_interval = "5s"
    }

    prometheus.remote_write "grafana_cloud" {
    endpoint {
        url = env("GC_METRICS_URL")
        basic_auth {
        username = env("GC_METRICS_USER")
        password = env("GC_TOKEN")
        }
    }
    }

    // ========== LOGS: read docker logs for demo-app ==========
    loki.source.docker "docker_logs" {
    host             = "unix:///var/run/docker.sock"
    targets          = [{ name = "demo-app" }]
    forward_to       = [loki.write.grafana_cloud.receiver]
    labels = {
        service = "demo-app",
        env     = "td",
    }
    }

    // Option: parse JSON logs & extract fields as labels (attention cardinalit√©!)
    loki.process "json" {
    forward_to = [loki.write.grafana_cloud.receiver]

    stage.json {
        expressions = {
        level = "level",
        route = "route",
        status = "status",
        }
    }

    // labels utiles (√©viter trace_id en label!)
    stage.labels {
        values = {
        level = "level",
        route = "route",
        status = "status",
        }
    }
    }

    loki.write "grafana_cloud" {
    endpoint {
        url = env("GC_LOKI_URL")
        basic_auth {
        username = env("GC_LOKI_USER")
        password = env("GC_TOKEN")
        }
    }
    }
```

> Si tu veux √™tre ‚Äúsafe‚Äù c√¥t√© cardinalit√© : garde `level` et `route` en labels, mais √©vite tout identifiant unique !!!!!

---

### 4.4 App de d√©mo (Python minimal) `demo-app/app.py`

```python
    import os, json, time, random, uuid
    from flask import Flask, request, Response
    from prometheus_client import Counter, Histogram, Gauge, generate_latest, CONTENT_TYPE_LATEST

    APP_NAME = os.getenv("APP_NAME", "demo-app")
    APP_VERSION = os.getenv("APP_VERSION", "1.0.0")

    app = Flask(__name__)

    http_requests_total = Counter(
        "http_requests_total", "Total HTTP requests",
        ["route", "method", "status"]
    )
    http_request_duration = Histogram(
        "http_request_duration_seconds", "HTTP request duration",
        ["route", "method"]
    )

    dataops_items_total = Counter(
        "dataops_items_total", "Items processed by result",
        ["result"]
    )
    dataops_batch_duration = Histogram(
        "dataops_batch_duration_seconds", "Batch processing duration seconds"
    )

    up = Gauge("app_up", "App up (1=up)")
    up.set(1)

    def log(level, msg, **fields):
        payload = {
            "level": level,
            "msg": msg,
            "service": APP_NAME,
            "version": APP_VERSION,
            "ts": int(time.time() * 1000),
            **fields,
        }
        print(json.dumps(payload), flush=True)

    @app.before_request
    def start_timer():
        request._t0 = time.time()

    @app.after_request
    def record_metrics(resp):
        route = request.path
        method = request.method
        status = str(resp.status_code)
        http_requests_total.labels(route=route, method=method, status=status).inc()
        http_request_duration.labels(route=route, method=method).observe(time.time() - request._t0)
        return resp

    @app.get("/")
    def index():
        log("info", "request", route="/", status=200, trace_id=str(uuid.uuid4()))
        return {"ok": True, "service": APP_NAME, "version": APP_VERSION}

    @app.get("/work")
    def work():
        items = int(request.args.get("items", "100"))
        batch_id = str(uuid.uuid4())[:8]
        t0 = time.time()

        invalid = 0
        for _ in range(items):
            if random.random() < 0.03:  # 3% invalid
                invalid += 1

        # simulate latency and occasional upstream issue
        time.sleep(random.random() * 0.08)
        if random.random() < 0.02:  # 2% upstream timeout
            log("error", "upstream_timeout", route="/work", status=504, batch_id=batch_id, items=items)
            dataops_items_total.labels(result="invalid").inc(invalid)
            return {"ok": False, "error": "upstream_timeout", "batch_id": batch_id}, 504

        duration = time.time() - t0
        dataops_batch_duration.observe(duration)

        dataops_items_total.labels(result="ok").inc(items - invalid)
        dataops_items_total.labels(result="invalid").inc(invalid)

        if invalid > 0:
            log("warn", "validation_failed", route="/work", status=200, batch_id=batch_id, items=items, invalid_items=invalid, duration_ms=int(duration*1000))
        log("info", "batch_processed", route="/work", status=200, batch_id=batch_id, items=items, invalid_items=invalid, duration_ms=int(duration*1000), trace_id=str(uuid.uuid4()))

        return {"ok": True, "batch_id": batch_id, "items": items, "invalid": invalid, "duration_ms": int(duration*1000)}

    @app.get("/metrics")
    def metrics():
        return Response(generate_latest(), mimetype=CONTENT_TYPE_LATEST)

    if __name__ == "__main__":
        log("info", "starting", port=8080)
        app.run(host="0.0.0.0", port=8080)
```

### 4.5 `demo-app/Dockerfile`

```dockerfile
    FROM python:3.12-slim
    WORKDIR /app
    RUN pip install --no-cache-dir flask prometheus-client
    COPY app.py /app/app.py
    EXPOSE 8080
    CMD ["python", "app.py"]
```

---

### 4.6 Prometheus local (optionnel) `prometheus/prometheus.yml`

```yaml
    global:
    scrape_interval: 5s

    scrape_configs:
    - job_name: "demo-app"
        static_configs:
        - targets: ["demo-app:8080"]
```

---

## 5) Exposer les metrics/logs de votre app

### √âtape A ‚Äî Lancer la stack

  ```bash
  docker compose up --build
  ```

V√©rifs rapides :

* App : `http://localhost:8080/`
* Metrics : `http://localhost:8080/metrics`
* G√©n√©rer du trafic :

  * `http://localhost:8080/work?items=200` (√† faire 10‚Äì20 fois)
* Prometheus local (optionnel) : `http://localhost:9090`

---

### √âtape B ‚Äî V√©rifier arriv√©e des m√©triques dans Grafana Cloud

Dans Grafana Cloud ‚Üí Explore ‚Üí Metrics (PromQL), tester :

* `sum(rate(http_requests_total[1m]))`
* `histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))`
* `sum(rate(dataops_items_total{result="invalid"}[5m]))`

---

### √âtape C ‚Äî V√©rifier arriv√©e des logs dans Loki

Dans Grafana Cloud ‚Üí Explore ‚Üí Logs (LogQL), tester :

* `{service="demo-app"}`
* `{service="demo-app"} |= "validation_failed"`
* `{service="demo-app", level="error"}`

---

## 6) Construire le dashboard ‚ÄúDevOps Feedback Loop‚Äù (consignes)

Cr√©er un dashboard avec 6 panels (minimum) :

1. **RPS (req/s)**
   PromQL :

  ```promql
  sum(rate(http_requests_total[1m]))
  ```

2. **Taux d‚Äôerreur (%)** (HTTP 5xx)

  ```promql
  100 * sum(rate(http_requests_total{status=~"5.."}[5m]))
    / sum(rate(http_requests_total[5m]))
  ```

3. **Latence p95 (s)**

  ```promql
  histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))
  ```

4. **Items DataOps invalides / min**

  ```promql
  sum(rate(dataops_items_total{result="invalid"}[1m]))
  ```

5. **Logs r√©cents (table)**
   LogQL :

  ```logql
  {service="demo-app"} | json | line_format "{{.level}} {{.msg}} route={{.route}} status={{.status}} items={{.items}} invalid={{.invalid_items}}"
  ```

6. **Top erreurs (compte sur 10 min)**

  ```logql
  sum by (msg) (
    count_over_time({service="demo-app", level="error"} | json [10m])
  )
  ```

> Bonus corr√©lation : ajouter un dashboard variable `route` aliment√©e par `label_values(http_requests_total, route)` et filtrer panels + logs.

---

## 7) Partie ‚ÄúDevOps‚Äù (discussion guid√©e / Questions d'un bon √©l√®ve NAIL)

* Pourquoi avoir **m√©triques + logs** plut√¥t qu‚Äôun seul des deux ?
* Quel indicateur te donne :

  * le **sympt√¥me** ? (erreurs, latence)
  * la **cause probable** ? (logs error upstream_timeout)
* O√π placerais-tu ton objectif applicatif  ?

  * ex : ‚Äú99% des requ√™tes < 60s sur 7 jours‚Äù
* Qu‚Äôest-ce que c'est une **bonne alerte** ?

---

## Mon point de vue de prof : 

C'est un outil de collect de log/metrics qui a les m√™mes standards qu'OpenTelemetry
Lisez bien la documentation de Grafana Alloy :

[https://grafana.com/docs/grafana-cloud/send-data/alloy/introduction/](https://grafana.com/docs/grafana-cloud/send-data/alloy/introduction/)

![https://grafana.com/docs/grafana-cloud/send-data/alloy/introduction/](alloy_schema.png)